{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-c4ea6782-8575-4d8a-8adc-ea7f04d0cfb0",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b1565e37",
        "execution_start": 1639122549139,
        "execution_millis": 16,
        "deepnote_cell_type": "code",
        "id": "Kmbw0jwcXOUv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import pickle"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u02GKX2-GDzY",
        "outputId": "b0a80d45-0ace-492a-e135-e6f817e1019a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('./drive/MyDrive/NLP')"
      ],
      "metadata": {
        "id": "oEVRS-0oGspM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xml_data = open('./dataset/articles-training-byarticle-20181122.xml', 'r').read()  # Read file\n",
        "root = ET.XML(xml_data)\n",
        "\n",
        "data = []\n",
        "\n",
        "for i, child in enumerate(root):\n",
        "    data.append([subchild.text for subchild in child])\n",
        "\n",
        "df = pd.DataFrame(data).T  # Write in DF and transpose it\n",
        "\n",
        "print(data[218])"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00001-fbf916f6-4ef1-407e-9851-b98809d801a6",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e699dc6f",
        "execution_start": 1639122666555,
        "execution_millis": 624,
        "deepnote_output_heights": [
          61
        ],
        "deepnote_cell_type": "code",
        "id": "YOxsGbwbXOU6",
        "outputId": "fa8ff6d0-7265-45f4-edc7-078bcd26f8d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hollywood will not easily recover from Harvey Weinstein -- not for a long time. The hypocrisy level has hit Defcon 1, 9.9 on the Richter scale.', \"Hollywood’s politics have always been a self-serving charade, a liberal masquerade for a rapacious and lubricious lifestyle. But now, thanks to the Weinstein scandal, we see it more clearly than ever. And it couldn't be more repellent. (I had always thought Bill Clinton would have made the greatest studio executive of all time. Now I'm convinced of it.)\", 'If conservative investors had any courage, this would be the time to make a hostile takeover of the movie business. Unfortunately, they don’t. I know this from bitter personal experience. Wealthy conservatives are delighted to support the Philharmonic, but when it comes to popular culture they turn away, as if afraid to get their hands dirty.', 'That this is a huge mistake should be obvious. They have abandoned the culture -- and our children -- to the creepiest people imaginable. What is going on in Hollywood is far from being just about Harvey. It’s approaching a pandemic. So many previously silent assaulted or raped women are coming out of the woodwork, it seems like a long-belated remake of “Cheaper by the Dozen.” No one knows who will be next or if it will stop at Harvey.', 'The rot is everywhere, even, perhaps especially, in the precincts of “high art.” Gwyneth Paltrow says now is the time to put an end to these attacks on women. But where was she years ago when Harvey got “handsy” with her? Looking the other way while earning millions and garnering Oscars. Meryl Streep claimed she was clueless about Weinstein’s repulsive antics. Time to award her her greatest Oscar yet -- for playing someone deaf, dumb, and blind while living as a troglodyte in the Gobi desert. Either the woman’s a liar or an utter nincompoop. I’ll go with the former.', 'As for the great feminist George Clooney -- the first male star out of the box to condemn Weinstein’s behavior -- let’s give him the Nobel Prize in virtue signaling. By coming forward, he was able to ace out his competition -- Howard Zinn-loving Matt Damon, who disgraced himself forever by covering up for Harvey a decade ago. (For those who may have missed it in the onslaught of sleazy details, Damon assured then New York Times reporter Sharon Waxman that Miramax’s high-paid Italian representative was a genuine “creative film executive” and not Harvey’s European procurer, as was, evidently correctly, rumored. Damon is the same “progressive” movie star who makes films opposing school choice for the masses while living in a thirty million dollar house and sending his kids to private school. I take it back -- maybe we should give him the Nobel in virtue signaling.)']\n"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "# loading labels\n",
        "xml_data1 = open('./dataset/ground-truth-training-byarticle-20181122.xml', 'r').read()  # Read file\n",
        "root1 = ET.XML(xml_data1)\n",
        "\n",
        "labels = []\n",
        "\n",
        "for i, child in enumerate(root1):\n",
        "    if child.attrib['hyperpartisan']=='true':\n",
        "        labels.append(1)\n",
        "    else:\n",
        "        labels.append(0)\n",
        "\n",
        "print(len(labels))"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00002-e9842289-461f-4240-832f-2f52e2627434",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a0a4487c",
        "execution_start": 1639123215470,
        "execution_millis": 698,
        "deepnote_cell_type": "code",
        "id": "F1ZnUCmZXOU_",
        "outputId": "b938c5f4-b9fe-43c6-e76a-31dda6962ee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "645\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "ratio = 0.1\n",
        "\n",
        "perm = np.random.permutation(len(data))\n",
        "idx_train = perm[:int(len(data)*(1-ratio))]\n",
        "idx_test = perm[int(len(data)*(1-ratio)):]\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "X_train = data[idx_train]\n",
        "y_train = labels[idx_train]\n",
        "\n",
        "X_test = data[idx_test]\n",
        "y_test = labels[idx_test]\n",
        "\n",
        "print(len(X_train),len(y_train))\n",
        "print(len(X_test),len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4DCZEA91j25",
        "outputId": "8ec2f598-e45f-4e25-cb13-82fb0ff403b8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "580 580\n",
            "65 65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AftZowqEAem9",
        "outputId": "981bcc86-3f4e-4baf-ad02-dead807465c1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize data\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "sentences = []  # 2D list\n",
        "for article in X_train:\n",
        "  for paragraph in article:\n",
        "    s = sent_tokenize(str(paragraph)) # sentence\n",
        "    \n",
        "    for single_sentence in s:\n",
        "      sentences += [tokenizer.tokenize(single_sentence.lower())]\n",
        "    \n",
        "sentences[55]"
      ],
      "metadata": {
        "id": "14AZmpEwEwW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3a2395-20f8-49c2-ca3b-b14118f51647"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gop']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "index_to_word = {}\n",
        "words_without_repitions = set()\n",
        "\n",
        "for line in sentences:\n",
        "  for j in line:\n",
        "    words_without_repitions.add(j)\n",
        "\n",
        "index = 0\n",
        "for i in words_without_repitions:\n",
        "  word_to_index[i]=index;\n",
        "  index_to_word[index] = i;\n",
        "  index+=1;"
      ],
      "metadata": {
        "id": "pHlQUSDjnhQQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CBOW"
      ],
      "metadata": {
        "id": "FU22gFY-mPl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(N,V):\n",
        "    W1 = np.random.rand(N, V)\n",
        "    W2 = np.random.rand(V, N)\n",
        "    b1 = np.random.rand(N, 1)\n",
        "    b2 = np.random.rand(V, 1)\n",
        "    return W1, W2, b1, b2\n",
        "\n",
        "def get_vectors(final_words, word_to_index, V , line ,j):\n",
        "    x1 = np.zeros(V)\n",
        "    x2 = np.zeros(V)\n",
        "    x3 = np.zeros(V)\n",
        "    x4 = np.zeros(V)\n",
        "    sum = np.zeros(V)\n",
        "    divisor = 0;\n",
        "    if(j-2>=0):\n",
        "      divisor+=1\n",
        "      x1[word_to_index[line[j-2]]]=1;\n",
        "    if(j-1>=0):\n",
        "      divisor+=1\n",
        "      x2[word_to_index[line[j-1]]]=1;\n",
        "    if(j+1<len(line)):\n",
        "      divisor+=1\n",
        "      x3[word_to_index[line[j+1]]]=1;\n",
        "    if(j+2<len(line)):\n",
        "      divisor+=1\n",
        "      x4[word_to_index[line[j+2]]]=1;\n",
        "\n",
        "    if(j-2>=0):\n",
        "      sum=sum+np.divide(x1,divisor)\n",
        "    if(j-1>=0):\n",
        "      sum=sum+np.divide(x2,divisor)\n",
        "    if(j+1<len(line)):\n",
        "      sum=sum+np.divide(x3,divisor)\n",
        "    if(j+2<len(line)):\n",
        "      sum=sum+np.divide(x4,divisor)\n",
        "\n",
        "    out = np.zeros(V)\n",
        "    out[word_to_index[line[j]]]=1;\n",
        "    return sum,out\n",
        "\n",
        "line = 0\n",
        "j=0;\n",
        "def get_batch(final_words, word_to_index, V, batch_size):\n",
        "    global batches\n",
        "    input = []\n",
        "    output = []\n",
        "    for line in final_words:\n",
        "      for j in range(len(line)):\n",
        "        x,y = get_vectors(final_words ,word_to_index , V, line,j)\n",
        "        if len(input) < batch_size:\n",
        "            input.append(x)\n",
        "            output.append(y)\n",
        "        else:\n",
        "            copy1 = np.empty_like(input)\n",
        "            copy1[:] = input\n",
        "\n",
        "            copy2 = np.empty_like(output)\n",
        "            copy2[:] = output\n",
        "\n",
        "            input = []\n",
        "            output = []\n",
        "            # print(copy1)\n",
        "            # print(copy2)\n",
        "            yield np.array(copy1).T, np.array(copy2).T\n",
        "\n",
        "    # return np.array(input).T, np.array(output).T\n",
        "\n",
        "def softmax(z):\n",
        "    e_z = np.exp(z)\n",
        "    yhat = e_z/np.sum(e_z, axis=0)\n",
        "    return yhat\n",
        "\n",
        "def forward_prop(x, W1, W2, b1, b2):\n",
        "    h = np.dot(W1, x)\n",
        "    z = np.dot(W2, h)\n",
        "    return z, h\n",
        "\n",
        "def back_prop(x, yhat, y, h, W1, W2, b1, b2, batch_size):\n",
        "    l1 = np.dot(W2.T, yhat - y)\n",
        "    # l1 = np.maximum(l1, 0)\n",
        "    grad_W1 = np.dot(l1, x.T) / batch_size\n",
        "    grad_W2 = np.dot(yhat - y, h.T) / batch_size\n",
        "    grad_b1 = np.sum(l1, axis = 1, keepdims = True) / batch_size\n",
        "    grad_b2 = np.sum(yhat - y, axis = 1, keepdims = True) / batch_size\n",
        "    \n",
        "    return grad_W1, grad_W2, grad_b1, grad_b2"
      ],
      "metadata": {
        "id": "l450f2CLmYT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V = len(words_without_repitions)\n",
        "num_iters = 50000\n",
        "N = 100\n",
        "alpha = 0.03\n",
        "\n",
        "def gradient_descent():\n",
        "    global costs\n",
        "    W1, W2, b1, b2 = initialize_model(N, V)\n",
        "    batch_size = 10\n",
        "    iters = 0\n",
        "    while True:\n",
        "        # [v for v in get_batch(final_words, word_to_index, V, batch_size)]\n",
        "        # x = v[0]\n",
        "        # y = v[1]\n",
        "\n",
        "        for x,y in get_batch(sentences, word_to_index, V, batch_size):\n",
        "          z, h = forward_prop(x, W1, W2, b1, b2)\n",
        "          yhat = softmax(z)\n",
        "          \n",
        "          grad_W1, grad_W2, grad_b1, grad_b2 = back_prop(x, yhat, y, h, W1, W2, b1, b2, batch_size)\n",
        "\n",
        "          W1 -= alpha * grad_W1 \n",
        "          W2 -= alpha * grad_W2\n",
        "          b1 -= alpha * grad_b1\n",
        "          b2 -= alpha * grad_b2\n",
        "\n",
        "          iters += 1\n",
        "          if iters == num_iters: \n",
        "              break\n",
        "\n",
        "        if iters == num_iters: \n",
        "              break    \n",
        "    return W2\n",
        "\n",
        "w = gradient_descent()\n",
        "  \n",
        "print(w)"
      ],
      "metadata": {
        "id": "ihfACV84mQ4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f35d0a04-70e4-45c1-d182-2de87de63d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.07531571 0.34446108 0.39229854 ... 0.07314928 1.00974848 0.9056541 ]\n",
            " [0.32503526 0.03193449 0.45110166 ... 0.83899605 0.03489792 0.28134073]\n",
            " [0.4266793  0.88102249 0.97944737 ... 0.91044364 0.2615907  0.52856089]\n",
            " ...\n",
            " [0.72776307 0.28644043 0.40280095 ... 0.01107635 0.97562479 0.81080025]\n",
            " [0.39712116 0.90699151 0.10138985 ... 0.50880765 0.21259988 0.57561217]\n",
            " [0.76874967 0.93171665 0.33796807 ... 0.36539586 0.18993712 0.61253675]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# store embeddings\n",
        "ans = []\n",
        "for i in range(0,len(w)):\n",
        "  ans.append(w[i])\n",
        "\n",
        "file_name = \"embedding.pkl\"\n",
        "\n",
        "open_file = open(file_name, \"wb\")\n",
        "pickle.dump(ans, open_file)\n",
        "open_file.close()\n",
        "\n",
        "file_name = \"word_to_index.pkl\"\n",
        "\n",
        "open_file = open(file_name, \"wb\")\n",
        "pickle.dump(word_to_index, open_file)\n",
        "open_file.close()"
      ],
      "metadata": {
        "id": "ELZoCcM2N1Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading embeddings\n",
        "w = pickle.load(open('embedding.pkl', 'rb'))\n",
        "word_to_index = pickle.load(open('word_to_index.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "bg6UhqQNG_Vj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index['c']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOe-DfbdIkxH",
        "outputId": "89b17e4e-1d40-45e7-b4fb-07ab8b5e4a53"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10178"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(X_train).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c_YT6hpomjM",
        "outputId": "2d7d8cf6-6325-4737-eb47-a02d03161c2d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(580,)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing data for the classifier\n",
        "\n",
        "article_feature_vec = []\n",
        "for article in X_train:\n",
        "\n",
        "  sentence_embedding = []\n",
        "  for paragraph in article:\n",
        "    s = sent_tokenize(str(paragraph))\n",
        "    for sentence in s:\n",
        "      val = []\n",
        "      for word in sentence:\n",
        "        if word in word_to_index: # check if word is present\n",
        "          val.append(np.mean(w[word_to_index[word]]))\n",
        "      if len(val):\n",
        "        sentence_embedding.append(np.mean(val))\n",
        "      \n",
        "  article_feature_vec += [sentence_embedding]"
      ],
      "metadata": {
        "id": "6wOxGnzwRCMG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_embedding = pd.DataFrame(article_feature_vec)\n",
        "article_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "O7Ihev82ZFN0",
        "outputId": "9ed5a190-79ed-446d-b5db-d6d995814bd0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.572775</td>\n",
              "      <td>0.571560</td>\n",
              "      <td>0.564736</td>\n",
              "      <td>0.577231</td>\n",
              "      <td>0.564554</td>\n",
              "      <td>0.572686</td>\n",
              "      <td>0.582387</td>\n",
              "      <td>0.568886</td>\n",
              "      <td>0.561590</td>\n",
              "      <td>0.572899</td>\n",
              "      <td>0.578270</td>\n",
              "      <td>0.575884</td>\n",
              "      <td>0.570324</td>\n",
              "      <td>0.565057</td>\n",
              "      <td>0.531325</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.531325</td>\n",
              "      <td>0.565731</td>\n",
              "      <td>0.581676</td>\n",
              "      <td>0.556979</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.577120</td>\n",
              "      <td>0.576445</td>\n",
              "      <td>0.575460</td>\n",
              "      <td>0.571758</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.531325</td>\n",
              "      <td>0.570516</td>\n",
              "      <td>0.565557</td>\n",
              "      <td>0.574467</td>\n",
              "      <td>0.570219</td>\n",
              "      <td>0.571594</td>\n",
              "      <td>0.572267</td>\n",
              "      <td>0.568794</td>\n",
              "      <td>0.577528</td>\n",
              "      <td>0.565341</td>\n",
              "      <td>0.571973</td>\n",
              "      <td>0.569791</td>\n",
              "      <td>0.569627</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.574396</td>\n",
              "      <td>0.576557</td>\n",
              "      <td>0.576057</td>\n",
              "      <td>0.576367</td>\n",
              "      <td>0.576006</td>\n",
              "      <td>0.572814</td>\n",
              "      <td>0.571083</td>\n",
              "      <td>0.574107</td>\n",
              "      <td>0.579404</td>\n",
              "      <td>0.564947</td>\n",
              "      <td>0.577099</td>\n",
              "      <td>0.587182</td>\n",
              "      <td>0.579030</td>\n",
              "      <td>0.575869</td>\n",
              "      <td>0.568521</td>\n",
              "      <td>0.585412</td>\n",
              "      <td>0.581157</td>\n",
              "      <td>0.575059</td>\n",
              "      <td>0.572619</td>\n",
              "      <td>0.568951</td>\n",
              "      <td>0.573539</td>\n",
              "      <td>0.569337</td>\n",
              "      <td>0.573644</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>0.566507</td>\n",
              "      <td>0.560991</td>\n",
              "      <td>0.570621</td>\n",
              "      <td>0.574943</td>\n",
              "      <td>0.575574</td>\n",
              "      <td>0.582014</td>\n",
              "      <td>0.544238</td>\n",
              "      <td>0.568745</td>\n",
              "      <td>0.573172</td>\n",
              "      <td>0.574327</td>\n",
              "      <td>0.582501</td>\n",
              "      <td>0.576362</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>0.563341</td>\n",
              "      <td>0.568854</td>\n",
              "      <td>0.571712</td>\n",
              "      <td>0.577151</td>\n",
              "      <td>0.579402</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>0.608212</td>\n",
              "      <td>0.571513</td>\n",
              "      <td>0.531325</td>\n",
              "      <td>0.575726</td>\n",
              "      <td>0.570671</td>\n",
              "      <td>0.557407</td>\n",
              "      <td>0.567391</td>\n",
              "      <td>0.583405</td>\n",
              "      <td>0.568151</td>\n",
              "      <td>0.574809</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>0.570336</td>\n",
              "      <td>0.563572</td>\n",
              "      <td>0.570564</td>\n",
              "      <td>0.565048</td>\n",
              "      <td>0.563291</td>\n",
              "      <td>0.565579</td>\n",
              "      <td>0.565387</td>\n",
              "      <td>0.555277</td>\n",
              "      <td>0.584334</td>\n",
              "      <td>0.568798</td>\n",
              "      <td>0.558080</td>\n",
              "      <td>0.568935</td>\n",
              "      <td>0.568264</td>\n",
              "      <td>0.574086</td>\n",
              "      <td>0.570953</td>\n",
              "      <td>0.570259</td>\n",
              "      <td>0.560731</td>\n",
              "      <td>0.562987</td>\n",
              "      <td>0.566424</td>\n",
              "      <td>0.569347</td>\n",
              "      <td>0.572218</td>\n",
              "      <td>0.574559</td>\n",
              "      <td>0.574716</td>\n",
              "      <td>0.569811</td>\n",
              "      <td>0.572482</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>0.575929</td>\n",
              "      <td>0.575404</td>\n",
              "      <td>0.570598</td>\n",
              "      <td>0.572331</td>\n",
              "      <td>0.566275</td>\n",
              "      <td>0.586355</td>\n",
              "      <td>0.569603</td>\n",
              "      <td>0.587422</td>\n",
              "      <td>0.580944</td>\n",
              "      <td>0.570670</td>\n",
              "      <td>0.572362</td>\n",
              "      <td>0.585161</td>\n",
              "      <td>0.572933</td>\n",
              "      <td>0.581696</td>\n",
              "      <td>0.575355</td>\n",
              "      <td>0.567518</td>\n",
              "      <td>0.581270</td>\n",
              "      <td>0.554749</td>\n",
              "      <td>0.597801</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>580 rows × 156 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4    ...  151  152  153  154  155\n",
              "0    0.572775  0.571560  0.564736  0.577231  0.564554  ...  NaN  NaN  NaN  NaN  NaN\n",
              "1    0.531325  0.565731  0.581676  0.556979       NaN  ...  NaN  NaN  NaN  NaN  NaN\n",
              "2    0.577120  0.576445  0.575460  0.571758       NaN  ...  NaN  NaN  NaN  NaN  NaN\n",
              "3    0.531325  0.570516  0.565557  0.574467  0.570219  ...  NaN  NaN  NaN  NaN  NaN\n",
              "4    0.574396  0.576557  0.576057  0.576367  0.576006  ...  NaN  NaN  NaN  NaN  NaN\n",
              "..        ...       ...       ...       ...       ...  ...  ...  ...  ...  ...  ...\n",
              "575  0.566507  0.560991  0.570621  0.574943  0.575574  ...  NaN  NaN  NaN  NaN  NaN\n",
              "576  0.563341  0.568854  0.571712  0.577151  0.579402  ...  NaN  NaN  NaN  NaN  NaN\n",
              "577  0.608212  0.571513  0.531325  0.575726  0.570671  ...  NaN  NaN  NaN  NaN  NaN\n",
              "578  0.570336  0.563572  0.570564  0.565048  0.563291  ...  NaN  NaN  NaN  NaN  NaN\n",
              "579  0.575929  0.575404  0.570598  0.572331  0.566275  ...  NaN  NaN  NaN  NaN  NaN\n",
              "\n",
              "[580 rows x 156 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only the columns with at least 1/4 non-NA values.\n",
        "article_embedding.dropna(thresh=article_embedding.shape[0]/4, axis=1, inplace=True)\n",
        "article_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "_UmkBrZzgJM_",
        "outputId": "ab7df5d1-8c42-4033-f629-bceb3d38e9ae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.572775</td>\n",
              "      <td>0.571560</td>\n",
              "      <td>0.564736</td>\n",
              "      <td>0.577231</td>\n",
              "      <td>0.564554</td>\n",
              "      <td>0.572686</td>\n",
              "      <td>0.582387</td>\n",
              "      <td>0.568886</td>\n",
              "      <td>0.561590</td>\n",
              "      <td>0.572899</td>\n",
              "      <td>0.578270</td>\n",
              "      <td>0.575884</td>\n",
              "      <td>0.570324</td>\n",
              "      <td>0.565057</td>\n",
              "      <td>0.531325</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.531325</td>\n",
              "      <td>0.565731</td>\n",
              "      <td>0.581676</td>\n",
              "      <td>0.556979</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.577120</td>\n",
              "      <td>0.576445</td>\n",
              "      <td>0.575460</td>\n",
              "      <td>0.571758</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.531325</td>\n",
              "      <td>0.570516</td>\n",
              "      <td>0.565557</td>\n",
              "      <td>0.574467</td>\n",
              "      <td>0.570219</td>\n",
              "      <td>0.571594</td>\n",
              "      <td>0.572267</td>\n",
              "      <td>0.568794</td>\n",
              "      <td>0.577528</td>\n",
              "      <td>0.565341</td>\n",
              "      <td>0.571973</td>\n",
              "      <td>0.569791</td>\n",
              "      <td>0.569627</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.574396</td>\n",
              "      <td>0.576557</td>\n",
              "      <td>0.576057</td>\n",
              "      <td>0.576367</td>\n",
              "      <td>0.576006</td>\n",
              "      <td>0.572814</td>\n",
              "      <td>0.571083</td>\n",
              "      <td>0.574107</td>\n",
              "      <td>0.579404</td>\n",
              "      <td>0.564947</td>\n",
              "      <td>0.577099</td>\n",
              "      <td>0.587182</td>\n",
              "      <td>0.579030</td>\n",
              "      <td>0.575869</td>\n",
              "      <td>0.568521</td>\n",
              "      <td>0.585412</td>\n",
              "      <td>0.581157</td>\n",
              "      <td>0.575059</td>\n",
              "      <td>0.572619</td>\n",
              "      <td>0.568951</td>\n",
              "      <td>0.573539</td>\n",
              "      <td>0.569337</td>\n",
              "      <td>0.573644</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>0.566507</td>\n",
              "      <td>0.560991</td>\n",
              "      <td>0.570621</td>\n",
              "      <td>0.574943</td>\n",
              "      <td>0.575574</td>\n",
              "      <td>0.582014</td>\n",
              "      <td>0.544238</td>\n",
              "      <td>0.568745</td>\n",
              "      <td>0.573172</td>\n",
              "      <td>0.574327</td>\n",
              "      <td>0.582501</td>\n",
              "      <td>0.576362</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>0.563341</td>\n",
              "      <td>0.568854</td>\n",
              "      <td>0.571712</td>\n",
              "      <td>0.577151</td>\n",
              "      <td>0.579402</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>0.608212</td>\n",
              "      <td>0.571513</td>\n",
              "      <td>0.531325</td>\n",
              "      <td>0.575726</td>\n",
              "      <td>0.570671</td>\n",
              "      <td>0.557407</td>\n",
              "      <td>0.567391</td>\n",
              "      <td>0.583405</td>\n",
              "      <td>0.568151</td>\n",
              "      <td>0.574809</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>0.570336</td>\n",
              "      <td>0.563572</td>\n",
              "      <td>0.570564</td>\n",
              "      <td>0.565048</td>\n",
              "      <td>0.563291</td>\n",
              "      <td>0.565579</td>\n",
              "      <td>0.565387</td>\n",
              "      <td>0.555277</td>\n",
              "      <td>0.584334</td>\n",
              "      <td>0.568798</td>\n",
              "      <td>0.558080</td>\n",
              "      <td>0.568935</td>\n",
              "      <td>0.568264</td>\n",
              "      <td>0.574086</td>\n",
              "      <td>0.570953</td>\n",
              "      <td>0.570259</td>\n",
              "      <td>0.560731</td>\n",
              "      <td>0.562987</td>\n",
              "      <td>0.566424</td>\n",
              "      <td>0.569347</td>\n",
              "      <td>0.572218</td>\n",
              "      <td>0.574559</td>\n",
              "      <td>0.574716</td>\n",
              "      <td>0.569811</td>\n",
              "      <td>0.572482</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>0.575929</td>\n",
              "      <td>0.575404</td>\n",
              "      <td>0.570598</td>\n",
              "      <td>0.572331</td>\n",
              "      <td>0.566275</td>\n",
              "      <td>0.586355</td>\n",
              "      <td>0.569603</td>\n",
              "      <td>0.587422</td>\n",
              "      <td>0.580944</td>\n",
              "      <td>0.570670</td>\n",
              "      <td>0.572362</td>\n",
              "      <td>0.585161</td>\n",
              "      <td>0.572933</td>\n",
              "      <td>0.581696</td>\n",
              "      <td>0.575355</td>\n",
              "      <td>0.567518</td>\n",
              "      <td>0.581270</td>\n",
              "      <td>0.554749</td>\n",
              "      <td>0.597801</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>580 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2         3         4   ...  29  30  31  32  33\n",
              "0    0.572775  0.571560  0.564736  0.577231  0.564554  ... NaN NaN NaN NaN NaN\n",
              "1    0.531325  0.565731  0.581676  0.556979       NaN  ... NaN NaN NaN NaN NaN\n",
              "2    0.577120  0.576445  0.575460  0.571758       NaN  ... NaN NaN NaN NaN NaN\n",
              "3    0.531325  0.570516  0.565557  0.574467  0.570219  ... NaN NaN NaN NaN NaN\n",
              "4    0.574396  0.576557  0.576057  0.576367  0.576006  ... NaN NaN NaN NaN NaN\n",
              "..        ...       ...       ...       ...       ...  ...  ..  ..  ..  ..  ..\n",
              "575  0.566507  0.560991  0.570621  0.574943  0.575574  ... NaN NaN NaN NaN NaN\n",
              "576  0.563341  0.568854  0.571712  0.577151  0.579402  ... NaN NaN NaN NaN NaN\n",
              "577  0.608212  0.571513  0.531325  0.575726  0.570671  ... NaN NaN NaN NaN NaN\n",
              "578  0.570336  0.563572  0.570564  0.565048  0.563291  ... NaN NaN NaN NaN NaN\n",
              "579  0.575929  0.575404  0.570598  0.572331  0.566275  ... NaN NaN NaN NaN NaN\n",
              "\n",
              "[580 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_embedding.fillna(method='ffill',axis=1,inplace=True)\n",
        "article_embedding[-5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "2hB2J2_jlbGl",
        "outputId": "04f43143-19f8-4544-cfd3-e9711373a5a7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>0.566507</td>\n",
              "      <td>0.560991</td>\n",
              "      <td>0.570621</td>\n",
              "      <td>0.574943</td>\n",
              "      <td>0.575574</td>\n",
              "      <td>0.582014</td>\n",
              "      <td>0.544238</td>\n",
              "      <td>0.568745</td>\n",
              "      <td>0.573172</td>\n",
              "      <td>0.574327</td>\n",
              "      <td>0.582501</td>\n",
              "      <td>0.576362</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "      <td>0.570759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>0.563341</td>\n",
              "      <td>0.568854</td>\n",
              "      <td>0.571712</td>\n",
              "      <td>0.577151</td>\n",
              "      <td>0.579402</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "      <td>0.585123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>0.608212</td>\n",
              "      <td>0.571513</td>\n",
              "      <td>0.531325</td>\n",
              "      <td>0.575726</td>\n",
              "      <td>0.570671</td>\n",
              "      <td>0.557407</td>\n",
              "      <td>0.567391</td>\n",
              "      <td>0.583405</td>\n",
              "      <td>0.568151</td>\n",
              "      <td>0.574809</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "      <td>0.564097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>0.570336</td>\n",
              "      <td>0.563572</td>\n",
              "      <td>0.570564</td>\n",
              "      <td>0.565048</td>\n",
              "      <td>0.563291</td>\n",
              "      <td>0.565579</td>\n",
              "      <td>0.565387</td>\n",
              "      <td>0.555277</td>\n",
              "      <td>0.584334</td>\n",
              "      <td>0.568798</td>\n",
              "      <td>0.558080</td>\n",
              "      <td>0.568935</td>\n",
              "      <td>0.568264</td>\n",
              "      <td>0.574086</td>\n",
              "      <td>0.570953</td>\n",
              "      <td>0.570259</td>\n",
              "      <td>0.560731</td>\n",
              "      <td>0.562987</td>\n",
              "      <td>0.566424</td>\n",
              "      <td>0.569347</td>\n",
              "      <td>0.572218</td>\n",
              "      <td>0.574559</td>\n",
              "      <td>0.574716</td>\n",
              "      <td>0.569811</td>\n",
              "      <td>0.572482</td>\n",
              "      <td>0.572482</td>\n",
              "      <td>0.572482</td>\n",
              "      <td>0.572482</td>\n",
              "      <td>0.572482</td>\n",
              "      <td>0.572482</td>\n",
              "      <td>0.572482</td>\n",
              "      <td>0.572482</td>\n",
              "      <td>0.572482</td>\n",
              "      <td>0.572482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>0.575929</td>\n",
              "      <td>0.575404</td>\n",
              "      <td>0.570598</td>\n",
              "      <td>0.572331</td>\n",
              "      <td>0.566275</td>\n",
              "      <td>0.586355</td>\n",
              "      <td>0.569603</td>\n",
              "      <td>0.587422</td>\n",
              "      <td>0.580944</td>\n",
              "      <td>0.570670</td>\n",
              "      <td>0.572362</td>\n",
              "      <td>0.585161</td>\n",
              "      <td>0.572933</td>\n",
              "      <td>0.581696</td>\n",
              "      <td>0.575355</td>\n",
              "      <td>0.567518</td>\n",
              "      <td>0.581270</td>\n",
              "      <td>0.554749</td>\n",
              "      <td>0.597801</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "      <td>0.552859</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2   ...        31        32        33\n",
              "575  0.566507  0.560991  0.570621  ...  0.570759  0.570759  0.570759\n",
              "576  0.563341  0.568854  0.571712  ...  0.585123  0.585123  0.585123\n",
              "577  0.608212  0.571513  0.531325  ...  0.564097  0.564097  0.564097\n",
              "578  0.570336  0.563572  0.570564  ...  0.572482  0.572482  0.572482\n",
              "579  0.575929  0.575404  0.570598  ...  0.552859  0.552859  0.552859\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(article_embedding.isnull().sum().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YHYr3wmqWUO",
        "outputId": "2ad26848-cbc0-4984-9bfa-59cbf6f7d05e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_embedding.fillna(method='bfill',axis=1,inplace=True)\n",
        "article_embedding.fillna(0,inplace=True)\n",
        "print(article_embedding.isnull().sum().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jFM4VmfrL0F",
        "outputId": "fd11772c-16af-467c-f7f4-c80778597c9a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameter tuning\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "hyper_params = {\n",
        "    'n_estimators': range(100,1000,100),\n",
        "    'criterion': ['gini','entropy'],\n",
        "    'max_depth': range(3,20),\n",
        "    # 'min_samples_leaf': range(5,100),\n",
        "    'random_state': range(0,100),\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}"
      ],
      "metadata": {
        "id": "_8gHrg-MZzP-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomizedSearchCV(RandomForestClassifier(), hyper_params)\n",
        "\n",
        "# Training\n",
        "clf.fit(article_embedding, y_train)\n",
        "\n",
        "model = clf.best_estimator_\n",
        "print(model)"
      ],
      "metadata": {
        "id": "kZ_HlEZWdQsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34edca6b-0aa4-4f6e-bfe9-c6ca7971fd8c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_depth=12, max_features='sqrt', n_estimators=900,\n",
            "                       random_state=48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing test data\n",
        "article_feature_vec = []\n",
        "for article in X_test:\n",
        "\n",
        "  sentence_embedding = []\n",
        "  for paragraph in article:\n",
        "    s = sent_tokenize(str(paragraph))\n",
        "    for sentence in s:\n",
        "      val = []\n",
        "      for word in sentence:\n",
        "        if word in word_to_index: # check if word is present\n",
        "          val.append(np.mean(w[word_to_index[word]]))\n",
        "      if len(val):\n",
        "        sentence_embedding.append(np.mean(val))\n",
        "      \n",
        "  article_feature_vec += [sentence_embedding]"
      ],
      "metadata": {
        "id": "wQPFOzKj1XuU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.DataFrame(article_feature_vec)\n",
        "\n",
        "# change dimension according to train data\n",
        "del_cols = test_data.shape[1]-article_embedding.shape[1]\n",
        "test_data = test_data.iloc[:,:-del_cols]\n",
        "\n",
        "test_data.fillna(method='ffill',axis=1,inplace=True)\n",
        "test_data.fillna(method='bfill',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "2sNW2fB-sRQx"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_data)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "3ajMzkSpeC_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5fcf295-12e8-4961-afd3-33d10d149347"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred)*100,'%')\n",
        "print(\"F1 Score: \", metrics.f1_score(y_test, y_pred)*100,'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji1QKtH8w-wk",
        "outputId": "0a5abe8c-87ee-4caf-878f-47daaa9446fe"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  64.61538461538461 %\n",
            "F1 Score:  46.51162790697674 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNeGVCIzxiJv",
        "outputId": "1916e1f1-6033-4dc2-821b-7d932aa638fb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.82      0.74        39\n",
            "           1       0.59      0.38      0.47        26\n",
            "\n",
            "    accuracy                           0.65        65\n",
            "   macro avg       0.63      0.60      0.60        65\n",
            "weighted avg       0.64      0.65      0.63        65\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "plt.subplots(figsize=(10, 6))\n",
        "sns.heatmap(cm, annot = True, fmt = 'g')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "6FfATvGu8sIJ",
        "outputId": "69d693d9-7c2d-4443-aca2-d1ee243cb908"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gensim model\n",
        "Testing the same concept using gensim embeddings for bias detection"
      ],
      "metadata": {
        "id": "-LElf9TOKMod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "# !gzip -d GoogleNews-vectors-negative300.bin.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSZkJ1P1Gikk",
        "outputId": "1894e9b0-74c0-4b7b-a0db-d9c8dba7fb3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-10 18:37:12--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.64.251\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.64.251|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  47.8MB/s    in 34s     \n",
            "\n",
            "2021-12-10 18:37:46 (46.6 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
        "print('Found %s word vectors of word2vec' % len(word2vec.vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_Ye6uuPU6Ek",
        "outputId": "63df245f-4eee-429c-e3e6-976723fb295d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000000 word vectors of word2vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec['camera'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd4M55ytKN4R",
        "outputId": "939014e0-556f-4c91-e1c6-5072559a067d"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing data for the classifier\n",
        "\n",
        "# X_train,X_train = 2D list\n",
        "# returns dataframe\n",
        "def prepare_data(X_train,X_test,thresh=None):\n",
        "  # train data\n",
        "  article_feature_vec = []\n",
        "  for article in X_train:\n",
        "\n",
        "    sentence_embedding = []\n",
        "    for paragraph in article:\n",
        "      s = sent_tokenize(str(paragraph))\n",
        "      for sentence in s:\n",
        "        val = []\n",
        "        for word in sentence:\n",
        "          if word in word2vec: # check if word is present\n",
        "            val.append(np.mean(word2vec[word]))\n",
        "        if len(val):\n",
        "          sentence_embedding.append(np.mean(val))\n",
        "        \n",
        "    article_feature_vec += [sentence_embedding]\n",
        "  \n",
        "  ret = pd.DataFrame(article_feature_vec)\n",
        "  ret.dropna(thresh=ret.shape[0]*thresh, axis=1, inplace=True)\n",
        "\n",
        "  ret.fillna(method='ffill',axis=1,inplace=True)\n",
        "  ret.fillna(method='bfill',axis=1,inplace=True)\n",
        "  ret.fillna(0,inplace=True)\n",
        "\n",
        "  # test data\n",
        "  article_feature_vec = []\n",
        "  for article in X_test:\n",
        "\n",
        "    sentence_embedding = []\n",
        "    for paragraph in article:\n",
        "      s = sent_tokenize(str(paragraph))\n",
        "      for sentence in s:\n",
        "        val = []\n",
        "        for word in sentence:\n",
        "          if word in word2vec: # check if word is present\n",
        "            val.append(np.mean(word2vec[word]))\n",
        "        if len(val):\n",
        "          sentence_embedding.append(np.mean(val))\n",
        "        \n",
        "    article_feature_vec += [sentence_embedding]\n",
        "  \n",
        "  ret2 = pd.DataFrame(article_feature_vec)\n",
        "  del_cols = ret2.shape[1]-ret.shape[1]\n",
        "  ret2 = ret2.iloc[:,:-del_cols]\n",
        "\n",
        "  ret2.fillna(method='ffill',axis=1,inplace=True)\n",
        "  ret2.fillna(method='bfill',axis=1,inplace=True)\n",
        "  ret2.fillna(0,inplace=True)\n",
        "  \n",
        "  return ret,ret2\n",
        "\n",
        "gensim_train_data, gensim_test_data = prepare_data(X_train, X_test, thresh=0.25)"
      ],
      "metadata": {
        "id": "yZ5rNLDrJvP1"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gensim_train_data)\n",
        "print(gensim_test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHyPbc-ehHac",
        "outputId": "3df14d39-df4e-4392-8c83-e64effc9da8e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           0         1         2   ...        31        32        33\n",
            "0   -0.005024 -0.006143 -0.006147  ... -0.009518 -0.009518 -0.009518\n",
            "1   -0.009518 -0.004481 -0.005257  ... -0.001960 -0.001960 -0.001960\n",
            "2   -0.005521 -0.005013 -0.004803  ... -0.005131 -0.005131 -0.005131\n",
            "3   -0.009518 -0.005140 -0.005861  ... -0.005692 -0.005692 -0.005692\n",
            "4   -0.004588 -0.005273 -0.005203  ... -0.004750 -0.004750 -0.004750\n",
            "..        ...       ...       ...  ...       ...       ...       ...\n",
            "575 -0.005570 -0.005961 -0.004564  ... -0.008992 -0.008992 -0.008992\n",
            "576 -0.005472 -0.007113 -0.005386  ... -0.004402 -0.004402 -0.004402\n",
            "577 -0.002103 -0.005642 -0.009518  ... -0.007630 -0.007630 -0.007630\n",
            "578 -0.003384 -0.002067 -0.005902  ... -0.003446 -0.003446 -0.003446\n",
            "579 -0.006173 -0.005809 -0.004975  ... -0.008142 -0.008142 -0.008142\n",
            "\n",
            "[580 rows x 34 columns]\n",
            "          0         1         2   ...        31        32        33\n",
            "0  -0.006087 -0.006087 -0.006087  ... -0.006087 -0.006087 -0.006087\n",
            "1  -0.004659 -0.006708 -0.004911  ... -0.007158 -0.007158 -0.007158\n",
            "2  -0.004113 -0.007452 -0.005581  ... -0.009518 -0.009518 -0.009518\n",
            "3  -0.009518 -0.006302 -0.005108  ... -0.006743 -0.006743 -0.006743\n",
            "4  -0.004457 -0.005536 -0.005161  ... -0.004606 -0.004606 -0.004606\n",
            "..       ...       ...       ...  ...       ...       ...       ...\n",
            "60 -0.001608 -0.005725 -0.005624  ... -0.003207 -0.003207 -0.003207\n",
            "61 -0.004997 -0.004640 -0.005994  ... -0.005255 -0.005255 -0.005255\n",
            "62 -0.004245 -0.009518 -0.005253  ... -0.006454 -0.006454 -0.006454\n",
            "63 -0.006011 -0.002044 -0.004298  ... -0.008699 -0.008699 -0.008699\n",
            "64 -0.004238 -0.003922 -0.005805  ... -0.003025 -0.003025 -0.003025\n",
            "\n",
            "[65 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators = 400)\n",
        "clf.fit(gensim_train_data, y_train)\n",
        "y_pred = clf.predict(gensim_test_data)"
      ],
      "metadata": {
        "id": "oHrse_k4O_D6"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred)*100,'%')\n",
        "print(\"F1 Score: \", metrics.f1_score(y_test, y_pred)*100,'%')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZYTK8IPPJqJ",
        "outputId": "e85a63af-851f-4e4a-8a42-0b1275198c14"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  55.38461538461539 %\n",
            "F1 Score:  29.268292682926834 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.77      0.67        39\n",
            "           1       0.40      0.23      0.29        26\n",
            "\n",
            "    accuracy                           0.55        65\n",
            "   macro avg       0.50      0.50      0.48        65\n",
            "weighted avg       0.52      0.55      0.52        65\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GloVe model"
      ],
      "metadata": {
        "id": "dhMx-KfEJKjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate http://nlp.stanford.edu/data/glove.6B.zip -O /tmp/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFsfZqEkJNe2",
        "outputId": "a45e2a4c-e0a6-4154-dd0d-94d46a552fe8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-11 15:43:51--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-12-11 15:43:51--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-12-11 15:43:52--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘/tmp/glove.6B.zip’\n",
            "\n",
            "/tmp/glove.6B.zip   100%[===================>] 822.24M  5.07MB/s    in 2m 40s  \n",
            "\n",
            "2021-12-11 15:46:32 (5.13 MB/s) - ‘/tmp/glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/tmp/glove.6B.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/tmp/glove')"
      ],
      "metadata": {
        "id": "SI-_Ld0zKDU7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "f = open('/tmp/glove/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGVc1-pgKcgf",
        "outputId": "a6faccbe-843d-4f35-9808-ca98ad9e6cb2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, max_length))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "qQ5vlQM6KpEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings_index[\"camera\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg80-sqLK37n",
        "outputId": "dcd13132-7775-41b9-d634-bb9b3a8cacbf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.15433   -0.64416    0.10601    0.29336    0.15603    0.26157\n",
            " -0.062361   0.39104    0.27071   -0.1475     0.68665   -0.35519\n",
            " -0.059875  -0.25777    0.65901    0.53279   -0.31004    0.3868\n",
            "  0.79289   -0.30342   -0.21298   -0.079137  -0.13125   -0.30356\n",
            "  1.0597    -0.10637    0.11868    0.30544    0.054878  -0.10311\n",
            "  0.2921     0.59605   -0.91195    1.132      1.0783    -0.33453\n",
            " -0.23376   -0.26142    1.3293    -0.76971    0.12998   -0.40786\n",
            " -0.32376    0.43906   -1.0648    -0.31423   -0.077851  -0.06993\n",
            "  0.18887   -0.019047  -0.1836     0.17368   -0.066262   1.6467\n",
            "  0.55081   -1.8841    -0.41274    0.35008    1.1006    -0.49432\n",
            "  0.46349    1.499      0.0046456  0.73574    0.052391   0.31359\n",
            "  0.53659   -0.061741  -0.32042    1.1158     0.20671    0.065164\n",
            "  1.0298     0.14286    0.095693   0.12563    0.24062    0.064921\n",
            "  0.26017   -0.063592   0.41458   -0.047662   0.22585   -0.18949\n",
            " -1.715     -0.23938    0.54405    0.12833    0.51828   -0.6509\n",
            "  0.29557    0.37531    0.98658   -0.41509    0.2457     0.33539\n",
            " -0.44183    0.087079   0.97158   -0.26339  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing data for the classifier\n",
        "\n",
        "# X_train,X_train = 2D list\n",
        "# returns dataframe\n",
        "def prepare_data(X_train,X_test,thresh=None):\n",
        "  # train data\n",
        "  article_feature_vec = []\n",
        "  for article in X_train:\n",
        "\n",
        "    sentence_embedding = []\n",
        "    for paragraph in article:\n",
        "      s = sent_tokenize(str(paragraph))\n",
        "      for sentence in s:\n",
        "        val = []\n",
        "        for word in sentence:\n",
        "          if word in embeddings_index:\n",
        "            val.append(np.mean(embeddings_index[word]))\n",
        "        if len(val):\n",
        "          sentence_embedding.append(np.mean(val))\n",
        "        \n",
        "    article_feature_vec += [sentence_embedding]\n",
        "  \n",
        "  ret = pd.DataFrame(article_feature_vec)\n",
        "  ret.dropna(thresh=ret.shape[0]*thresh, axis=1, inplace=True)\n",
        "\n",
        "  ret.fillna(method='ffill',axis=1,inplace=True)\n",
        "  ret.fillna(method='bfill',axis=1,inplace=True)\n",
        "  ret.fillna(0,inplace=True)\n",
        "\n",
        "  # test data\n",
        "  article_feature_vec = []\n",
        "  for article in X_test:\n",
        "\n",
        "    sentence_embedding = []\n",
        "    for paragraph in article:\n",
        "      s = sent_tokenize(str(paragraph))\n",
        "      for sentence in s:\n",
        "        val = []\n",
        "        for word in sentence:\n",
        "          if word in embeddings_index:\n",
        "            val.append(np.mean(embeddings_index[word]))\n",
        "        if len(val):\n",
        "          sentence_embedding.append(np.mean(val))\n",
        "        \n",
        "    article_feature_vec += [sentence_embedding]\n",
        "  \n",
        "  ret2 = pd.DataFrame(article_feature_vec)\n",
        "  del_cols = ret2.shape[1]-ret.shape[1]\n",
        "  ret2 = ret2.iloc[:,:-del_cols]\n",
        "\n",
        "  ret2.fillna(method='ffill',axis=1,inplace=True)\n",
        "  ret2.fillna(method='bfill',axis=1,inplace=True)\n",
        "  ret2.fillna(0,inplace=True)\n",
        "  \n",
        "  return ret,ret2\n",
        "\n",
        "glove_train_data, glove_test_data = prepare_data(X_train, X_test, thresh=0.25)"
      ],
      "metadata": {
        "id": "MDRHljXPLcwV"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators = 900)\n",
        "clf.fit(glove_train_data, y_train)\n",
        "y_pred = clf.predict(glove_test_data)"
      ],
      "metadata": {
        "id": "Zu5xLabBOHEd"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred)*100,'%')\n",
        "print(\"F1 Score: \", metrics.f1_score(y_test, y_pred)*100,'%')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNGuHVVAOHtE",
        "outputId": "fffcde6b-49c2-4017-ace5-57f53ac6cd30"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  63.07692307692307 %\n",
            "F1 Score:  36.84210526315789 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.72      0.74        47\n",
            "           1       0.35      0.39      0.37        18\n",
            "\n",
            "    accuracy                           0.63        65\n",
            "   macro avg       0.55      0.56      0.55        65\n",
            "weighted avg       0.64      0.63      0.64        65\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "plt.subplots(figsize=(10, 6))\n",
        "sns.heatmap(cm, annot = True, fmt = 'g')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "PlDDqGkAOQHl",
        "outputId": "874e4525-04d4-4505-cdd1-146651e4c4dd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_notebook_id": "7a2dfc84-1f1e-4c23-a857-5eff1049d4cf",
    "deepnote_execution_queue": [],
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-LElf9TOKMod"
      ]
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  }
}